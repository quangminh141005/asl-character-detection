{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Load dataset from kaggle"
      ],
      "metadata": {
        "id": "DceLtUHCK4kS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rHsMWS_wLKSC",
        "outputId": "5d829ae1-7408-4594-9d8d-56ffc84b3f8c"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install kaggle\n",
        "! mkdir ~/.kaggle\n",
        "! cp /content/drive/MyDrive/kaggle/kaggle.json ~/.kaggle\n",
        "! chmod 600 ~/.kaggle/kaggle.json # 6 for owner, 0 for group and others"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jSAuFGuuLCaO",
        "outputId": "4bef04e3-140e-4148-b40d-e0d80b84f5ae"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.12/dist-packages (1.7.4.5)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.12/dist-packages (from kaggle) (6.3.0)\n",
            "Requirement already satisfied: certifi>=14.05.14 in /usr/local/lib/python3.12/dist-packages (from kaggle) (2025.10.5)\n",
            "Requirement already satisfied: charset-normalizer in /usr/local/lib/python3.12/dist-packages (from kaggle) (3.4.4)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from kaggle) (3.11)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.12/dist-packages (from kaggle) (5.29.5)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.12/dist-packages (from kaggle) (2.9.0.post0)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.12/dist-packages (from kaggle) (8.0.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from kaggle) (2.32.4)\n",
            "Requirement already satisfied: setuptools>=21.0.0 in /usr/local/lib/python3.12/dist-packages (from kaggle) (75.2.0)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.12/dist-packages (from kaggle) (1.17.0)\n",
            "Requirement already satisfied: text-unidecode in /usr/local/lib/python3.12/dist-packages (from kaggle) (1.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from kaggle) (4.67.1)\n",
            "Requirement already satisfied: urllib3>=1.15.1 in /usr/local/lib/python3.12/dist-packages (from kaggle) (2.5.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.12/dist-packages (from kaggle) (0.5.1)\n",
            "mkdir: cannot create directory â€˜/root/.kaggleâ€™: File exists\n",
            "Dataset URL: https://www.kaggle.com/datasets/alvarole/hand-and-face-detection-focused-on-sign-language\n",
            "License(s): apache-2.0\n",
            "^C\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install kagglehub"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u7OTMSUfPrpB",
        "outputId": "f4518301-6f6c-4cd8-f4da-69a6f3334362"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: kagglehub in /usr/local/lib/python3.12/dist-packages (0.3.13)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from kagglehub) (25.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.12/dist-packages (from kagglehub) (6.0.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from kagglehub) (2.32.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from kagglehub) (4.67.1)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->kagglehub) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->kagglehub) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->kagglehub) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->kagglehub) (2025.10.5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import kagglehub\n",
        "\n",
        "path = kagglehub.dataset_download(\"alvarole/hand-and-face-detection-focused-on-sign-language\")\n",
        "\n",
        "print(\"Path to dataset files:\", path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H8IAkwxNNsJS",
        "outputId": "ac19e5c5-97e2-41dc-96ae-0bf1d483e294"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Resuming download from 230686720 bytes (25390877758 bytes left)...\n",
            "Resuming download from https://www.kaggle.com/api/v1/datasets/download/alvarole/hand-and-face-detection-focused-on-sign-language?dataset_version_number=1 (230686720/25621564478) bytes left.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 23.9G/23.9G [03:58<00:00, 107MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting files...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Path to dataset files: /root/.cache/kagglehub/datasets/alvarole/hand-and-face-detection-focused-on-sign-language/versions/1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import random\n",
        "import shutil\n",
        "from pathlib import Path\n",
        "\n",
        "# === CONFIG ===\n",
        "ROOT_DIR = Path(\"/root/.cache/kagglehub/datasets/alvarole/hand-and-face-detection-focused-on-sign-language/versions/1/hand_face_detection_dataset\")\n",
        "SUBSET_DIR = Path(\"/content/subset\")\n",
        "\n",
        "# How many images you want to keep per split (edit these numbers as you like)\n",
        "TARGET_COUNTS = {\n",
        "    \"train\": 20000,       # e.g. 50k train images\n",
        "    \"validation\": 1000,  # e.g. 10k val images\n",
        "    \"test\": 50000         # e.g. 10k test images\n",
        "}\n",
        "\n",
        "# If True, will DELETE the original \"images\" and \"labels_yolo\" folders after creating subset\n",
        "DELETE_ORIGINAL = False  # <-- CHANGE TO True ONLY AFTER YOU CHECK THE SUBSET\n",
        "\n",
        "# Random seed for reproducibility\n",
        "random.seed(42)\n",
        "\n",
        "# === HELPER FUNCTIONS ===\n",
        "\n",
        "def list_image_files(folder):\n",
        "    exts = {\".jpg\", \".jpeg\", \".png\", \".bmp\"}\n",
        "    return [f for f in folder.iterdir() if f.suffix.lower() in exts]\n",
        "\n",
        "def ensure_dir(path: Path):\n",
        "    path.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# === MAIN LOGIC ===\n",
        "\n",
        "splits = [\"train\", \"validation\", \"test\"]\n",
        "\n",
        "for split in splits:\n",
        "    print(f\"\\n=== Processing split: {split} ===\")\n",
        "\n",
        "    img_dir = ROOT_DIR / \"images\" / split\n",
        "    lbl_dir = ROOT_DIR / \"labels_yolo\" / split\n",
        "\n",
        "    if not img_dir.exists():\n",
        "        print(f\"  [WARNING] Images folder does not exist: {img_dir}, skipping this split.\")\n",
        "        continue\n",
        "\n",
        "    if not lbl_dir.exists():\n",
        "        print(f\"  [WARNING] Labels folder does not exist: {lbl_dir}, skipping this split.\")\n",
        "        continue\n",
        "\n",
        "    # List all images in this split\n",
        "    img_files = list_image_files(img_dir)\n",
        "    num_images = len(img_files)\n",
        "    print(f\"  Found {num_images} images in {img_dir}\")\n",
        "\n",
        "    if num_images == 0:\n",
        "        print(\"  No images found, skipping.\")\n",
        "        continue\n",
        "\n",
        "    # Decide how many images to sample for this split\n",
        "    target = min(TARGET_COUNTS.get(split, num_images), num_images)\n",
        "    print(f\"  Sampling {target} images for subset.\")\n",
        "\n",
        "    sampled_imgs = random.sample(img_files, target)\n",
        "\n",
        "    # Create subset folders\n",
        "    subset_img_dir = SUBSET_DIR / \"images\" / split\n",
        "    subset_lbl_dir = SUBSET_DIR / \"labels_yolo\" / split\n",
        "    ensure_dir(subset_img_dir)\n",
        "    ensure_dir(subset_lbl_dir)\n",
        "\n",
        "    # Copy images + matching YOLO label files\n",
        "    for img_path in sampled_imgs:\n",
        "        # Copy image\n",
        "        dst_img_path = subset_img_dir / img_path.name\n",
        "        shutil.copy2(img_path, dst_img_path)\n",
        "\n",
        "        # Corresponding YOLO label (.txt)\n",
        "        label_name = img_path.stem + \".txt\"\n",
        "        src_label_path = lbl_dir / label_name\n",
        "        dst_label_path = subset_lbl_dir / label_name\n",
        "\n",
        "        if src_label_path.exists():\n",
        "            shutil.copy2(src_label_path, dst_label_path)\n",
        "        else:\n",
        "            # If there is no label file, you can either:\n",
        "            #  - create an empty .txt\n",
        "            #  - or skip it. Here we create an empty file.\n",
        "            dst_label_path.touch()\n",
        "            # print(f\"  [INFO] No label for {img_path.name}, created empty label.\")\n",
        "\n",
        "    print(f\"  Done split {split}. Subset images in: {subset_img_dir}\")\n",
        "    print(f\"  Subset labels in: {subset_lbl_dir}\")\n",
        "\n",
        "print(\"\\nâœ… Subset creation finished.\")\n",
        "print(f\"Subset root folder: {SUBSET_DIR}\")\n",
        "\n",
        "# === OPTIONAL: DELETE ORIGINAL LARGE FOLDERS ===\n",
        "if DELETE_ORIGINAL:\n",
        "    print(\"\\nâš ï¸ DELETE_ORIGINAL = True â†’ Deleting original 'images' and 'labels_yolo' folders...\")\n",
        "    orig_images = ROOT_DIR / \"images\"\n",
        "    orig_labels = ROOT_DIR / \"labels_yolo\"\n",
        "\n",
        "    if orig_images.exists():\n",
        "        shutil.rmtree(orig_images)\n",
        "        print(f\"  Deleted: {orig_images}\")\n",
        "\n",
        "    if orig_labels.exists():\n",
        "        shutil.rmtree(orig_labels)\n",
        "        print(f\"  Deleted: {orig_labels}\")\n",
        "\n",
        "    print(\"ðŸ—‘ï¸ Original dataset folders deleted.\")\n",
        "else:\n",
        "    print(\"\\nâ„¹ï¸ DELETE_ORIGINAL is False. Original dataset is kept.\")\n",
        "    print(\"   After you verify the subset, you can set DELETE_ORIGINAL = True and re-run the last block.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IZ7nRo8uP5f1",
        "outputId": "60bcf09c-ec6f-4044-b8a3-3f741ade0c96"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Processing split: train ===\n",
            "  Found 369053 images in /root/.cache/kagglehub/datasets/alvarole/hand-and-face-detection-focused-on-sign-language/versions/1/hand_face_detection_dataset/images/train\n",
            "  Sampling 20000 images for subset.\n",
            "  Done split train. Subset images in: /content/subset/images/train\n",
            "  Subset labels in: /content/subset/labels_yolo/train\n",
            "\n",
            "=== Processing split: validation ===\n",
            "  Found 59386 images in /root/.cache/kagglehub/datasets/alvarole/hand-and-face-detection-focused-on-sign-language/versions/1/hand_face_detection_dataset/images/validation\n",
            "  Sampling 1000 images for subset.\n",
            "  Done split validation. Subset images in: /content/subset/images/validation\n",
            "  Subset labels in: /content/subset/labels_yolo/validation\n",
            "\n",
            "=== Processing split: test ===\n",
            "  Found 49041 images in /root/.cache/kagglehub/datasets/alvarole/hand-and-face-detection-focused-on-sign-language/versions/1/hand_face_detection_dataset/images/test\n",
            "  Sampling 49041 images for subset.\n",
            "  Done split test. Subset images in: /content/subset/images/test\n",
            "  Subset labels in: /content/subset/labels_yolo/test\n",
            "\n",
            "âœ… Subset creation finished.\n",
            "Subset root folder: /content/subset\n",
            "\n",
            "â„¹ï¸ DELETE_ORIGINAL is False. Original dataset is kept.\n",
            "   After you verify the subset, you can set DELETE_ORIGINAL = True and re-run the last block.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# If True, will DELETE the original \"images\" and \"labels_yolo\" folders after creating subset\n",
        "DELETE_ORIGINAL = True  # <-- CHANGE TO True ONLY AFTER YOU CHECK THE SUBSET\n",
        "\n",
        "# Random seed for reproducibility\n",
        "random.seed(42)\n",
        "\n",
        "# === OPTIONAL: DELETE ORIGINAL LARGE FOLDERS ===\n",
        "if DELETE_ORIGINAL:\n",
        "    print(\"\\nâš ï¸ DELETE_ORIGINAL = True â†’ Deleting original 'images' and 'labels_yolo' folders...\")\n",
        "    orig_images = ROOT_DIR / \"images\"\n",
        "    orig_labels = ROOT_DIR / \"labels_yolo\"\n",
        "\n",
        "    if orig_images.exists():\n",
        "        shutil.rmtree(orig_images)\n",
        "        print(f\"  Deleted: {orig_images}\")\n",
        "\n",
        "    if orig_labels.exists():\n",
        "        shutil.rmtree(orig_labels)\n",
        "        print(f\"  Deleted: {orig_labels}\")\n",
        "\n",
        "    print(\"ðŸ—‘ï¸ Original dataset folders deleted.\")\n",
        "else:\n",
        "    print(\"\\nâ„¹ï¸ DELETE_ORIGINAL is False. Original dataset is kept.\")\n",
        "    print(\"   After you verify the subset, you can set DELETE_ORIGINAL = True and re-run the last block.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YhkWuYskWKG4",
        "outputId": "7ca0c498-33dc-46f4-8267-0a2e8444606d"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "âš ï¸ DELETE_ORIGINAL = True â†’ Deleting original 'images' and 'labels_yolo' folders...\n",
            "  Deleted: /root/.cache/kagglehub/datasets/alvarole/hand-and-face-detection-focused-on-sign-language/versions/1/hand_face_detection_dataset/images\n",
            "  Deleted: /root/.cache/kagglehub/datasets/alvarole/hand-and-face-detection-focused-on-sign-language/versions/1/hand_face_detection_dataset/labels_yolo\n",
            "ðŸ—‘ï¸ Original dataset folders deleted.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "ROOT = Path(\"\")\n",
        "\n",
        "splits = [\"train\", \"val\", \"test\"]\n",
        "\n",
        "for split in splits:\n",
        "    label_dir = ROOT / \"labels\" / split\n",
        "    img_dir = ROOT / \"images\" / split\n",
        "\n",
        "    print(f\"\\n=== Processing split: {split} ===\")\n",
        "\n",
        "    for label_file in label_dir.glob(\"*.txt\"):\n",
        "        new_lines = []\n",
        "\n",
        "        with open(label_file, \"r\") as f:\n",
        "            for line in f:\n",
        "                parts = line.strip().split()\n",
        "\n",
        "                if len(parts) < 5:\n",
        "                    continue\n",
        "\n",
        "                cls = parts[0]\n",
        "\n",
        "                if cls == \"0\":\n",
        "                    # remove face label\n",
        "                    continue\n",
        "\n",
        "                if cls == \"1\":\n",
        "                    # hand label -> change to 0\n",
        "                    parts[0] = \"0\"\n",
        "                    new_lines.append(\" \".join(parts))\n",
        "\n",
        "        # Save new label file (only hands)\n",
        "        with open(label_file, \"w\") as f:\n",
        "            for line in new_lines:\n",
        "                f.write(line + \"\\n\")\n",
        "\n",
        "        # OPTIONAL: delete image if no hand left\n",
        "        if len(new_lines) == 0:\n",
        "            img_path = img_dir / (label_file.stem + \".jpg\")\n",
        "            if img_path.exists():\n",
        "                img_path.unlink()   # delete image\n",
        "            label_file.unlink()      # delete empty label file\n",
        "\n",
        "    print(f\"Done processing {split}.\")"
      ],
      "metadata": {
        "id": "Y-hjoinrYKfn"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}